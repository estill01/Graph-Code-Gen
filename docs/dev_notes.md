Dynamic Graph Attention mechanisms



 [Graph Transformer: A Generalization of Transformers to Graphs][1]
 [PDF: Graph Transformer: A Generalization of Transformers to Graphs][2]

 [Graph Attention Networks][3]


 [A Generalization Of Transformers To Graphs][4]


 [Transformer-Based Representation Learning on Temporal Heterogeneous Graphs][11]


 [1]: https://towardsdatascience.com/graph-transformer-generalization-of-transformers-to-graphs-ead2448cff8b
 [2]: https://arxiv.org/abs/1911.06455
 [3]: https://arxiv.org/abs/1710.10903
 [4]: https://arxiv.org/abs/2012.09699

 [11]: https://link.springer.com/chapter/10.1007/978-3-031-25198-6_29


 ## Models
 [Graphormer -- clefourrier/graphormer-base-pcqm4mv2][5]
 [Do Transformers Really Perform Bad for Graph Representation?][6]

 [Mesh Graphormer][7]
 [PDF: MeshGraphormer][8] -- model local + global relationshipsc

 [NAGphormer][9] -- Enables Graphormer on large networks (important)
 [CODE: NAGphormer][10]


 [5]: https://huggingface.co/clefourrier/graphormer-base-pcqm4mv2
 [6]: https://arxiv.org/abs/2106.05234
 [7]: https://github.com/microsoft/MeshGraphormer
 [8]: https://openaccess.thecvf.com/content/ICCV2021/papers/Lin_Mesh_Graphormer_ICCV_2021_paper.pdf

 [9]: https://openreview.net/forum?id=8KYeilT3Ow
 [10]: https://github.com/JHL-HUST/NAGphormer

